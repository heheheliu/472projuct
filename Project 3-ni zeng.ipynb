{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdbb26b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\15145\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - gensim\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  python_abi         conda-forge/win-64::python_abi-3.8-2_cp38\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  conda              pkgs/main::conda-4.11.0-py38haa95532_0 --> conda-forge::conda-4.11.0-py38haa244fe_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33d46bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\15145\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - conda\n",
      "\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  python_abi-3.8-2_cp38\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  conda              conda-forge::conda-4.11.0-py38haa244f~ --> pkgs/main::conda-4.11.0-py38haa95532_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3aa9e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15145\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "#show all available models in gensim-data\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91d57b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_300=gensim.downloader.load('word2vec-google-news-300')#google 300 words embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81745c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dangerously\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('synonyms.csv','r') as synonyms_file:\n",
    "    read=csv.reader(synonyms_file)\n",
    "    read_file=list(read)\n",
    "    \n",
    "    print(read_file[3][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65196f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "analysis = []\n",
    "correct = 0\n",
    "guessed = 0\n",
    "with open(\"synonyms.csv\", \"r\") as f:\n",
    "    read = reader(f)\n",
    "    reader = list(read)\n",
    "    for i in range(1,len(reader)):\n",
    "        max_similarity = 0\n",
    "        guess = reader[i][2]\n",
    "        label = \"correct\"\n",
    "        if reader[i][0] in google_300 and ( reader[i][2] in google_300 or reader[i][3] in google_300 or reader[i][4] in google_300 or reader[i][5] in google_300):\n",
    "            label = \"correct\"\n",
    "            correct += 1\n",
    "        else:\n",
    "            label = \"guess\"\n",
    "            guessed += 1\n",
    "        for j in range(2,len(reader[i])):\n",
    "            try:\n",
    "                if max_similarity < google_300.similarity(reader[i][0], reader[i][j]):\n",
    "                    guess = reader[i][j]\n",
    "                    max_similarity = google_300.similarity(reader[i][0], reader[i][j])\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "        if (label !=\"guess\" and guess != reader[i][1]):\n",
    "            label = \"wrong\"\n",
    "            correct -= 1\n",
    "        analysis.append([reader[i][0]+\",\"+reader[i][1]+\",\"+guess+\",\"+label])     \n",
    "with open(\"word2vec-google-news-300-details.csv\", 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile)\n",
    "     wr.writerows(analysis)\n",
    " \n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f73c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_google300 = len(google_300)\n",
    "accuracy_google300 = correct/(80-guessed)\n",
    "total_google300 = 80-guessed\n",
    "\n",
    "row1 = \"word2vec-google-news-300\"+\",\"+str(corpus_google300)+\",\"+str(correct)+\",\"+str(total_google300)+\",\"+str(accuracy_google300)\n",
    "with open(\"00analysis.csv\", 'w', newline='') as analysisfile:\n",
    "     wr = csv.writer(analysisfile)\n",
    "     wr.writerows([[row1]])\n",
    "     analysisfile.write('n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0d4bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# task 2.1\n",
    "wiki_100=gensim.downloader.load('glove-wiki-gigaword-100')# 2 new models form different corpora \n",
    "twitter_100=gensim.downloader.load('glove-twitter-100')#but with same embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "852efb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "analysis = []\n",
    "correct = 0\n",
    "guessed = 0\n",
    "with open(\"synonyms.csv\", \"r\") as f:\n",
    "    read = reader(f)\n",
    "    reader = list(read)\n",
    "    for i in range(1,len(reader)):\n",
    "        max_similarity = 0\n",
    "        guess = reader[i][2]\n",
    "        label = \"correct\"\n",
    "        if reader[i][0] in wiki_100 and ( reader[i][2] in wiki_100 or reader[i][3] in wiki_100 or reader[i][4] in wiki_100 or reader[i][5] in wiki_100):\n",
    "            label = \"correct\"\n",
    "            correct += 1\n",
    "        else:\n",
    "            label = \"guess\"\n",
    "            guessed += 1\n",
    "        for j in range(2,len(reader[i])):\n",
    "            try:\n",
    "                if max_similarity < wiki_100.similarity(reader[i][0], reader[i][j]):\n",
    "                    guess = reader[i][j]\n",
    "                    max_similarity = wiki_100.similarity(reader[i][0], reader[i][j])\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "        if (label !=\"guess\" and guess != reader[i][1]):\n",
    "            label = \"wrong\"\n",
    "            correct -= 1\n",
    "        analysis.append([reader[i][0]+\",\"+reader[i][1]+\",\"+guess+\",\"+label])     \n",
    "with open(\"glove-wiki-gigaword-100-details.csv\", 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile)\n",
    "     wr.writerows(analysis)\n",
    "\n",
    "\n",
    "corpus = len(wiki_100)\n",
    "accuracy = correct/(80-guessed)\n",
    "total = 80-guessed\n",
    "\n",
    "row2= \"glove-wiki-gigaword-100\"+\",\"+str(corpus)+\",\"+str(correct)+\",\"+str(total)+\",\"+str(accuracy)\n",
    "#with open(\"00analysis.csv\", 'w', newline='') as analysisfile:\n",
    "    # wr = csv.writer(analysisfile)\n",
    "     #wr.writerows([[row]])\n",
    "     \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d34888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "analysis = []\n",
    "correct = 0\n",
    "guessed = 0\n",
    "with open(\"synonyms.csv\", \"r\") as f:\n",
    "    read = reader(f)\n",
    "    reader = list(read)\n",
    "    for i in range(1,len(reader)):\n",
    "        max_similarity = 0\n",
    "        guess = reader[i][2]\n",
    "        label = \"correct\"\n",
    "        if reader[i][0] in twitter_100 and ( reader[i][2] in twitter_100 or reader[i][3] in twitter_100 or reader[i][4] in twitter_100 or reader[i][5] in twitter_100):\n",
    "            label = \"correct\"\n",
    "            correct += 1\n",
    "        else:\n",
    "            label = \"guess\"\n",
    "            guessed += 1\n",
    "        for j in range(2,len(reader[i])):\n",
    "            try:\n",
    "                if max_similarity < twitter_100.similarity(reader[i][0], reader[i][j]):\n",
    "                    guess = reader[i][j]\n",
    "                    max_similarity = twitter_100.similarity(reader[i][0], reader[i][j])\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "        if (label !=\"guess\" and guess != reader[i][1]):\n",
    "            label = \"wrong\"\n",
    "            correct -= 1\n",
    "        analysis.append([reader[i][0]+\",\"+reader[i][1]+\",\"+guess+\",\"+label])     \n",
    "with open(\"glove-twitter-100-details.csv\", 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile)\n",
    "     wr.writerows(analysis)\n",
    "\n",
    "\n",
    "corpus = len(twitter_100)\n",
    "accuracy = correct/(80-guessed)\n",
    "total = 80-guessed\n",
    "row3 = \"glove-twitter-100\"+\",\"+str(corpus)+\",\"+str(correct)+\",\"+str(total)+\",\"+str(accuracy)\n",
    "#with open(\"00analysis.csv\", 'w', newline='') as analysisfile:\n",
    "     #wr = csv.writer(analysisfile)\n",
    "     #wr.writerows([[row]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5857a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 2.2\n",
    "twitter_25=gensim.downloader.load('glove-twitter-25')#2 new models from the same corpus but different embedding size\n",
    "twitter_50=gensim.downloader.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2cb109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "analysis = []\n",
    "correct = 0\n",
    "guessed = 0\n",
    "with open(\"synonyms.csv\", \"r\") as f:\n",
    "    read = reader(f)\n",
    "    reader = list(read)\n",
    "    for i in range(1,len(reader)):\n",
    "        max_similarity = 0\n",
    "        guess = reader[i][2]\n",
    "        label = \"correct\"\n",
    "        if reader[i][0] in twitter_25 and ( reader[i][2] in twitter_25 or reader[i][3] in twitter_25 or reader[i][4] in twitter_25 or reader[i][5] in twitter_25):\n",
    "            label = \"correct\"\n",
    "            correct += 1\n",
    "        else:\n",
    "            label = \"guess\"\n",
    "            guessed += 1\n",
    "        for j in range(2,len(reader[i])):\n",
    "            try:\n",
    "                if max_similarity < twitter_25.similarity(reader[i][0], reader[i][j]):\n",
    "                    guess = reader[i][j]\n",
    "                    max_similarity = twitter_25.similarity(reader[i][0], reader[i][j])\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "        if (label !=\"guess\" and guess != reader[i][1]):\n",
    "            label = \"wrong\"\n",
    "            correct -= 1\n",
    "        analysis.append([reader[i][0]+\",\"+reader[i][1]+\",\"+guess+\",\"+label])     \n",
    "with open(\"glove-twitter-25-details.csv\", 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile)\n",
    "     wr.writerows(analysis)\n",
    "    \n",
    "    \n",
    "\n",
    "corpus = len(twitter_25)\n",
    "accuracy = correct/(80-guessed)\n",
    "total = 80-guessed\n",
    "row4 = \"glove-twitter-25\"+\",\"+str(corpus)+\",\"+str(correct)+\",\"+str(total)+\",\"+str(accuracy)\n",
    "#with open(\"00analysis.csv\", 'w', newline='') as analysisfile:\n",
    "     #wr = csv.writer(analysisfile)\n",
    "     #wr.writerows([[row]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4d5f539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "analysis = []\n",
    "correct = 0\n",
    "guessed = 0\n",
    "with open(\"synonyms.csv\", \"r\") as f:\n",
    "    read = reader(f)\n",
    "    reader = list(read)\n",
    "    for i in range(1,len(reader)):\n",
    "        max_similarity = 0\n",
    "        guess = reader[i][2]\n",
    "        label = \"correct\"\n",
    "        if reader[i][0] in twitter_50 and ( reader[i][2] in twitter_50 or reader[i][3] in twitter_50 or reader[i][4] in twitter_50 or reader[i][5] in twitter_50):\n",
    "            label = \"correct\"\n",
    "            correct += 1\n",
    "        else:\n",
    "            label = \"guess\"\n",
    "            guessed += 1\n",
    "        for j in range(2,len(reader[i])):\n",
    "            try:\n",
    "                if max_similarity < twitter_50.similarity(reader[i][0], reader[i][j]):\n",
    "                    guess = reader[i][j]\n",
    "                    max_similarity = twitter_50.similarity(reader[i][0], reader[i][j])\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "        if (label !=\"guess\" and guess != reader[i][1]):\n",
    "            label = \"wrong\"\n",
    "            correct -= 1\n",
    "        analysis.append([reader[i][0]+\",\"+reader[i][1]+\",\"+guess+\",\"+label])     \n",
    "with open(\"glove-twitter-50-details.csv\", 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile)\n",
    "     wr.writerows(analysis)\n",
    "    \n",
    "    \n",
    "\n",
    "corpus = len(twitter_50)\n",
    "accuracy = correct/(80-guessed)\n",
    "total = 80-guessed\n",
    "row5 = \"glove-twitter-50\"+\",\"+str(corpus)+\",\"+str(correct)+\",\"+str(total)+\",\"+str(accuracy)\n",
    "with open(\"55analysis.csv\", 'w', newline='') as analysisfile:\n",
    "     wr = csv.writer(analysisfile)\n",
    "     wr.writerows([[row1]])\n",
    "     wr.writerows([[row2]])\n",
    "     wr.writerows([[row3]])\n",
    "     wr.writerows([[row4]])\n",
    "     wr.writerows([[row5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404347a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
